{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e92a7d10",
   "metadata": {},
   "source": [
    "# Heart Disease Prediction - Exploratory Data Analysis (EDA)\n",
    "\n",
    "## MLOps Assignment - Task 1: Data Acquisition & EDA\n",
    "\n",
    "**Objective:** Analyze the Heart Disease UCI Dataset to understand patterns, distributions, and relationships in the data.\n",
    "\n",
    "**Dataset:** Heart Disease UCI Dataset from UCI Machine Learning Repository\n",
    "- 303 instances from Cleveland Clinic Foundation\n",
    "- 14 attributes (13 features + 1 target)\n",
    "- Binary classification: Presence/Absence of heart disease\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2815d1fc",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ab58c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Configure visualization settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73feb73",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec9ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path\n",
    "BASE_DIR = Path.cwd().parent\n",
    "DATA_PATH = BASE_DIR / \"data\" / \"processed\" / \"heart_disease.csv\"\n",
    "\n",
    "print(f\"Loading data from: {DATA_PATH}\")\n",
    "\n",
    "# Check if file exists\n",
    "if DATA_PATH.exists():\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(f\"✓ Data loaded successfully!\")\n",
    "    print(f\"\\nDataset shape: {df.shape}\")\n",
    "    print(f\"Number of samples: {len(df)}\")\n",
    "    print(f\"Number of features: {len(df.columns) - 1}\")  # Excluding target\n",
    "else:\n",
    "    print(\"❌ Data file not found!\")\n",
    "    print(\"Please run: python ../src/download_data.py\")\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac13a55",
   "metadata": {},
   "source": [
    "## 3. Initial Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b616af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"=\"*80)\n",
    "print(\"FIRST 10 ROWS OF DATASET\")\n",
    "print(\"=\"*80)\n",
    "display(df.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LAST 5 ROWS OF DATASET\")\n",
    "print(\"=\"*80)\n",
    "display(df.tail())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATASET INFO\")\n",
    "print(\"=\"*80)\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COLUMN NAMES AND DATA TYPES\")\n",
    "print(\"=\"*80)\n",
    "for col in df.columns:\n",
    "    print(f\"{col:15s} : {str(df[col].dtype):10s} | Unique values: {df[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bd97b0",
   "metadata": {},
   "source": [
    "## 4. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9322432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "print(\"=\"*80)\n",
    "print(\"DESCRIPTIVE STATISTICS - ALL FEATURES\")\n",
    "print(\"=\"*80)\n",
    "display(df.describe().T.style.background_gradient(cmap='coolwarm'))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DESCRIPTIVE STATISTICS - TARGET VARIABLE\")\n",
    "print(\"=\"*80)\n",
    "print(df['target'].describe())\n",
    "print(f\"\\nTarget value counts:\")\n",
    "print(df['target'].value_counts().sort_index())\n",
    "print(f\"\\nTarget distribution (%):\")\n",
    "print(df['target'].value_counts(normalize=True).sort_index() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a757ba7d",
   "metadata": {},
   "source": [
    "## 5. Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caaac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"=\"*80)\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "missing_data = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df)) * 100\n",
    "})\n",
    "missing_data = missing_data[missing_data['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "if len(missing_data) > 0:\n",
    "    print(\"\\nColumns with missing values:\")\n",
    "    display(missing_data)\n",
    "    \n",
    "    # Visualize missing values\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    missing_data.plot(x='Column', y='Missing_Percentage', kind='bar', ax=ax, color='coral')\n",
    "    plt.title('Missing Values Percentage by Column', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Column')\n",
    "    plt.ylabel('Missing Percentage (%)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\n✓ No missing values found in the dataset!\")\n",
    "    print(\"This is excellent - the data is complete!\")\n",
    "\n",
    "print(f\"\\nTotal missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"Total data points: {df.shape[0] * df.shape[1]}\")\n",
    "print(f\"Missing percentage: {(df.isnull().sum().sum() / (df.shape[0] * df.shape[1])) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbd449c",
   "metadata": {},
   "source": [
    "## 6. Class Balance Analysis (TARGET VARIABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcce58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class balance analysis\n",
    "print(\"=\"*80)\n",
    "print(\"CLASS BALANCE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "target_counts = df['target'].value_counts().sort_index()\n",
    "target_percentages = df['target'].value_counts(normalize=True).sort_index() * 100\n",
    "\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(f\"Class 0 (No Disease):  {target_counts[0]:3d} samples ({target_percentages[0]:.2f}%)\")\n",
    "print(f\"Class 1 (Disease):     {target_counts[1]:3d} samples ({target_percentages[1]:.2f}%)\")\n",
    "print(f\"\\nClass Ratio: {target_counts[1] / target_counts[0]:.2f}:1\")\n",
    "\n",
    "# Visualize class distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Bar plot\n",
    "axes[0].bar(['No Disease (0)', 'Disease (1)'], target_counts.values, color=['#2ecc71', '#e74c3c'], alpha=0.7, edgecolor='black')\n",
    "axes[0].set_title('Class Distribution - Bar Chart', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(target_counts.values):\n",
    "    axes[0].text(i, v + 5, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "axes[1].pie(target_counts.values, labels=['No Disease (0)', 'Disease (1)'], \n",
    "           autopct='%1.1f%%', startangle=90, colors=colors, explode=(0.05, 0.05))\n",
    "axes[1].set_title('Class Distribution - Pie Chart', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Count plot with seaborn\n",
    "sns.countplot(data=df, x='target', ax=axes[2], palette=['#2ecc71', '#e74c3c'])\n",
    "axes[2].set_title('Class Distribution - Count Plot', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('Target (0: No Disease, 1: Disease)')\n",
    "axes[2].set_ylabel('Count')\n",
    "axes[2].set_xticklabels(['No Disease (0)', 'Disease (1)'])\n",
    "axes[2].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Balance assessment\n",
    "if abs(target_percentages[0] - target_percentages[1]) < 10:\n",
    "    print(\"\\n✓ Dataset is WELL BALANCED (difference < 10%)\")\n",
    "elif abs(target_percentages[0] - target_percentages[1]) < 20:\n",
    "    print(\"\\n⚠ Dataset is SLIGHTLY IMBALANCED (difference 10-20%)\")\n",
    "else:\n",
    "    print(\"\\n⚠ Dataset is IMBALANCED (difference > 20%)\")\n",
    "    print(\"  Consider using stratified sampling or class weights during training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df354a6f",
   "metadata": {},
   "source": [
    "## 7. Distribution Analysis - Histograms for All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db0ab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of all features\n",
    "print(\"=\"*80)\n",
    "print(\"FEATURE DISTRIBUTIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get all feature columns (exclude target)\n",
    "feature_cols = [col for col in df.columns if col != 'target']\n",
    "\n",
    "# Create subplots for histograms\n",
    "n_features = len(feature_cols)\n",
    "n_cols = 4\n",
    "n_rows = (n_features + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(feature_cols):\n",
    "    axes[idx].hist(df[col].dropna(), bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    axes[idx].set_title(f'{col} Distribution', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel(col)\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add mean and median lines\n",
    "    mean_val = df[col].mean()\n",
    "    median_val = df[col].median()\n",
    "    axes[idx].axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_val:.2f}')\n",
    "    axes[idx].axvline(median_val, color='green', linestyle='--', linewidth=2, label=f'Median: {median_val:.2f}')\n",
    "    axes[idx].legend(fontsize=8)\n",
    "\n",
    "# Hide extra subplots\n",
    "for idx in range(n_features, len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Distribution of All Features', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Histograms show the distribution shape for all features\")\n",
    "print(\"  - Red line: Mean\")\n",
    "print(\"  - Green line: Median\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d21f390",
   "metadata": {},
   "source": [
    "## 8. Correlation Analysis - Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aaa13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix and heatmap\n",
    "print(\"=\"*80)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Display correlations with target\n",
    "print(\"\\nCorrelations with Target Variable (sorted by absolute value):\")\n",
    "target_corr = correlation_matrix['target'].sort_values(ascending=False)\n",
    "print(target_corr)\n",
    "\n",
    "# Visualize correlation matrix\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Full correlation heatmap\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8}, ax=axes[0])\n",
    "axes[0].set_title('Correlation Heatmap - All Features', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Target correlation bar plot\n",
    "target_corr_abs = target_corr.drop('target').abs().sort_values(ascending=True)\n",
    "target_corr_abs.plot(kind='barh', ax=axes[1], color='teal')\n",
    "axes[1].set_title('Feature Correlations with Target (Absolute Values)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Absolute Correlation')\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify highly correlated features\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"HIGHLY CORRELATED FEATURE PAIRS (|correlation| > 0.5)\")\n",
    "print(\"=\"*80)\n",
    "high_corr = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.5:\n",
    "            high_corr.append({\n",
    "                'Feature 1': correlation_matrix.columns[i],\n",
    "                'Feature 2': correlation_matrix.columns[j],\n",
    "                'Correlation': correlation_matrix.iloc[i, j]\n",
    "            })\n",
    "\n",
    "if high_corr:\n",
    "    high_corr_df = pd.DataFrame(high_corr).sort_values('Correlation', ascending=False, key=abs)\n",
    "    display(high_corr_df)\n",
    "else:\n",
    "    print(\"No highly correlated feature pairs found (threshold: 0.5)\")\n",
    "\n",
    "print(\"\\n✓ Correlation analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292e2308",
   "metadata": {},
   "source": [
    "## 9. Box Plots - Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ad53fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for outlier detection\n",
    "print(\"=\"*80)\n",
    "print(\"OUTLIER DETECTION - BOX PLOTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create box plots for all numeric features\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(feature_cols):\n",
    "    axes[idx].boxplot(df[col].dropna(), vert=True, patch_artist=True,\n",
    "                     boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
    "                     medianprops=dict(color='red', linewidth=2),\n",
    "                     whiskerprops=dict(color='blue', linewidth=1.5),\n",
    "                     capprops=dict(color='blue', linewidth=1.5))\n",
    "    axes[idx].set_title(f'{col} - Box Plot', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_ylabel(col)\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Hide extra subplots\n",
    "for idx in range(n_features, len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Box Plots for All Features (Outlier Detection)', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate outliers using IQR method\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OUTLIER STATISTICS (IQR Method)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "outlier_summary = []\n",
    "for col in feature_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)][col]\n",
    "    outlier_count = len(outliers)\n",
    "    outlier_percentage = (outlier_count / len(df)) * 100\n",
    "    \n",
    "    outlier_summary.append({\n",
    "        'Feature': col,\n",
    "        'Q1': Q1,\n",
    "        'Q3': Q3,\n",
    "        'IQR': IQR,\n",
    "        'Lower_Bound': lower_bound,\n",
    "        'Upper_Bound': upper_bound,\n",
    "        'Outlier_Count': outlier_count,\n",
    "        'Outlier_Percentage': outlier_percentage\n",
    "    })\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_summary)\n",
    "outlier_df = outlier_df[outlier_df['Outlier_Count'] > 0].sort_values('Outlier_Count', ascending=False)\n",
    "\n",
    "if len(outlier_df) > 0:\n",
    "    print(\"\\nFeatures with outliers:\")\n",
    "    display(outlier_df)\n",
    "else:\n",
    "    print(\"\\n✓ No outliers detected using IQR method!\")\n",
    "\n",
    "print(\"\\n✓ Box plot analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a05b94f",
   "metadata": {},
   "source": [
    "## 10. Feature Relationships with Target Variable\n",
    "\n",
    "Analyze how each feature relates to the target variable (heart disease presence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817bf247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature relationships with target variable\n",
    "print(\"=\"*80)\n",
    "print(\"FEATURE-TARGET RELATIONSHIPS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create violin plots for continuous variables by target\n",
    "continuous_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "n_continuous = len(continuous_features)\n",
    "n_cols_violin = 3\n",
    "n_rows_violin = (n_continuous + n_cols_violin - 1) // n_cols_violin\n",
    "\n",
    "fig, axes = plt.subplots(n_rows_violin, n_cols_violin, figsize=(18, n_rows_violin * 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(continuous_features):\n",
    "    sns.violinplot(data=df, x='target', y=col, ax=axes[idx], palette='Set2')\n",
    "    axes[idx].set_title(f'{col} vs Target', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Target (0=No Disease, 1=Disease)')\n",
    "    axes[idx].set_ylabel(col)\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Hide extra subplots\n",
    "for idx in range(n_continuous, len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Continuous Features vs Target Variable (Violin Plots)', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create count plots for categorical variables by target\n",
    "categorical_features = [col for col in feature_cols if col not in continuous_features]\n",
    "n_categorical = len(categorical_features)\n",
    "n_rows_cat = (n_categorical + 2) // 3\n",
    "\n",
    "fig, axes = plt.subplots(n_rows_cat, 3, figsize=(18, n_rows_cat * 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(categorical_features):\n",
    "    # Grouped bar plot\n",
    "    pd.crosstab(df[col], df['target'], normalize='index').plot(\n",
    "        kind='bar', ax=axes[idx], color=['#FF6B6B', '#4ECDC4'], alpha=0.8\n",
    "    )\n",
    "    axes[idx].set_title(f'{col} vs Target (Normalized)', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel(col)\n",
    "    axes[idx].set_ylabel('Proportion')\n",
    "    axes[idx].legend(['No Disease', 'Disease'])\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "    axes[idx].set_xticklabels(axes[idx].get_xticklabels(), rotation=45)\n",
    "\n",
    "# Hide extra subplots\n",
    "for idx in range(n_categorical, len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Categorical Features vs Target Variable (Normalized Bar Plots)', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical summary by target\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MEAN VALUES BY TARGET CLASS\")\n",
    "print(\"=\"*80)\n",
    "target_means = df.groupby('target')[continuous_features].mean()\n",
    "display(target_means.style.background_gradient(cmap='RdYlGn', axis=0).format(\"{:.2f}\"))\n",
    "\n",
    "print(\"\\n✓ Feature-target relationship analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76daa53",
   "metadata": {},
   "source": [
    "## 11. Pairwise Feature Relationships\n",
    "\n",
    "Explore relationships between key features using pairplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4772f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot for key continuous features\n",
    "print(\"=\"*80)\n",
    "print(\"PAIRWISE RELATIONSHIPS - PAIRPLOT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Select key features for pairplot (to keep visualization manageable)\n",
    "key_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'target']\n",
    "\n",
    "print(f\"\\nGenerating pairplot for key features: {key_features[:-1]}\")\n",
    "print(\"This may take a moment...\\n\")\n",
    "\n",
    "# Create pairplot\n",
    "pairplot_fig = sns.pairplot(\n",
    "    df[key_features], \n",
    "    hue='target',\n",
    "    palette='Set1',\n",
    "    diag_kind='kde',\n",
    "    plot_kws={'alpha': 0.6},\n",
    "    height=2.5,\n",
    "    aspect=1.2\n",
    ")\n",
    "\n",
    "pairplot_fig.fig.suptitle('Pairwise Relationships of Key Features (colored by Target)', \n",
    "                          fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Pairplot analysis complete\")\n",
    "print(\"\\nKey Observations:\")\n",
    "print(\"- Diagonal: KDE plots show distribution of each feature by target class\")\n",
    "print(\"- Off-diagonal: Scatter plots show pairwise relationships\")\n",
    "print(\"- Red: No heart disease (target=0)\")\n",
    "print(\"- Blue: Heart disease present (target=1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7746498",
   "metadata": {},
   "source": [
    "## 12. Summary and Key Insights\n",
    "\n",
    "### Dataset Overview\n",
    "- **Total Records**: 303 patients\n",
    "- **Total Features**: 13 predictive features + 1 target variable\n",
    "- **Target Distribution**: Balanced dataset (presence vs. absence of heart disease)\n",
    "\n",
    "### Data Quality\n",
    "- **Missing Values**: No missing values detected ✓\n",
    "- **Data Types**: Mixed (numerical and categorical)\n",
    "- **Outliers**: Identified using IQR method in features like chol, trestbps, thalach\n",
    "\n",
    "### Key Findings from EDA\n",
    "\n",
    "#### 1. **Age Distribution**\n",
    "- Age ranges from 29 to 77 years\n",
    "- Mean age: ~54 years\n",
    "- Heart disease patients tend to be slightly older on average\n",
    "\n",
    "#### 2. **Sex-based Observations**\n",
    "- Dataset has more male patients\n",
    "- Disease prevalence differs between genders\n",
    "\n",
    "#### 3. **Chest Pain Type (cp)**\n",
    "- Strong predictor of heart disease\n",
    "- Different chest pain types show varying association with disease presence\n",
    "\n",
    "#### 4. **Blood Pressure & Cholesterol**\n",
    "- Resting blood pressure (trestbps): Mean ~131 mmHg\n",
    "- Serum cholesterol (chol): Mean ~246 mg/dl\n",
    "- Some outliers detected, but clinically plausible\n",
    "\n",
    "#### 5. **Maximum Heart Rate (thalach)**\n",
    "- Mean ~150 bpm\n",
    "- Patients with heart disease tend to have different thalach patterns\n",
    "\n",
    "#### 6. **ST Depression (oldpeak)**\n",
    "- Key indicator of heart disease\n",
    "- Positive correlation with disease presence\n",
    "\n",
    "#### 7. **Correlation Insights**\n",
    "- Strongest positive correlations with target: cp, thalach, slope\n",
    "- Strongest negative correlations with target: exang, oldpeak, ca\n",
    "- Some features show multicollinearity (consider feature engineering)\n",
    "\n",
    "### Recommendations for Modeling\n",
    "1. **Feature Engineering**: Consider interaction terms between highly correlated features\n",
    "2. **Scaling Required**: Features have different scales (age: 29-77, chol: 126-564)\n",
    "3. **Encoding**: Categorical variables (sex, cp, fbs, restecg, etc.) need encoding\n",
    "4. **Class Balance**: Dataset is relatively balanced - no need for SMOTE/undersampling\n",
    "5. **Model Selection**: Classification algorithms suitable (Logistic Regression, Random Forest, Gradient Boosting)\n",
    "\n",
    "### Next Steps\n",
    "- ✓ Data preprocessing (scaling, encoding)\n",
    "- ✓ Feature engineering\n",
    "- ✓ Model training with multiple algorithms\n",
    "- ✓ Hyperparameter tuning\n",
    "- ✓ Model evaluation with cross-validation\n",
    "\n",
    "---\n",
    "\n",
    "**EDA Complete** ✅"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
