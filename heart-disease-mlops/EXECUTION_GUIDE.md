# ðŸš€ MLOps Assignment - Complete Execution Guide

## âœ… Project Validation Against Requirements

### Task Completion Status

| Task | Requirement | Files/Evidence |
|------|------------|----------------|
| **1. Data Acquisition & EDA** | âœ… Download script<br>âœ… Data cleaning<br>âœ… Preprocessing<br>âœ… Professional visualizations | `src/download_data.py`<br>`notebooks/01_EDA.ipynb`<br>`src/preprocessing.py` |
| **2. Feature Engineering & Models** | âœ… Scaling/encoding<br>âœ… 2+ models (LR, RF, GB)<br>âœ… Cross-validation<br>âœ… Metrics evaluation | `src/train.py`<br>`src/preprocessing.py` |
| **3. Experiment Tracking** | âœ… MLflow integration<br>âœ… Log params/metrics<br>âœ… Artifacts storage | `src/train.py` (lines 50-200) |
| **4. Model Packaging** | âœ… Saved models<br>âœ… requirements.txt<br>âœ… Preprocessing pipeline | `models/best_model.pkl`<br>`models/preprocessor.pkl`<br>`requirements.txt` |
| **5. CI/CD Pipeline** | âœ… Unit tests<br>âœ… GitHub Actions<br>âœ… Linting/testing<br>âœ… Artifacts/logging | `tests/` folder<br>`.github/workflows/ci-cd.yml` |
| **6. Containerization** | âœ… Docker container<br>âœ… FastAPI with /predict<br>âœ… JSON input/output | `Dockerfile`<br>`src/app.py`<br>`sample_input.json` |
| **7. Production Deployment** | âœ… K8s manifests<br>âœ… Load Balancer/Ingress<br>âœ… Deployment instructions | `deployment/kubernetes/`<br>`docs/deployment_guide.md` |
| **8. Monitoring & Logging** | âœ… API logging<br>âœ… Prometheus + Grafana | `src/app.py` (logging)<br>`deployment/kubernetes/monitoring.yaml`<br>`docker-compose.yml` |
| **9. Documentation** | âœ… Setup instructions<br>âœ… Architecture diagram<br>âœ… Screenshots folder | `README.md`<br>`docs/`<br>`screenshots/` |

âœ… **All requirements implemented!**

---

## ðŸ“‹ Step-by-Step Execution Guide

### Phase 1: Environment Setup 

#### Step 1.1: Navigate to Project Directory
```bash
# Navigate to the heart-disease-mlops directory
cd heart-disease-mlops
```

#### Step 1.2: Run Setup Script
```bash
chmod +x setup.sh
./setup.sh
```
This will:
- Create Python virtual environment
- Install all dependencies from requirements.txt
- Create necessary directories
- Set up the environment

#### Step 1.3: Activate Virtual Environment
```bash
source venv/bin/activate
```

---

### Phase 2: Data Acquisition & EDA 

#### Step 2.1: Download Dataset
```bash
python src/download_data.py
```
**Expected Output:**
```
âœ“ Data downloaded successfully!
âœ“ Dataset saved to data/processed/heart_disease.csv
âœ“ Raw data copied to data/raw/
Dataset shape: (303, 14)
```

#### Step 2.2: Execute EDA Notebook
1. Open `notebooks/01_EDA.ipynb` in VS Code
2. **Run All Cells** (Shift + Enter on each cell or Run All)

---

### Phase 3: Model Training & Experiment Tracking

#### Step 3.1: Train Models with MLflow
```bash
python src/train.py
```

**Expected Output:**
```
âœ“ Data loaded successfully
âœ“ Preprocessing pipeline created
Training Logistic Regression...
âœ“ Logistic Regression - Accuracy: 0.85, ROC-AUC: 0.90
Training Random Forest...
âœ“ Random Forest - Accuracy: 0.88, ROC-AUC: 0.92
Training Gradient Boosting...
âœ“ Gradient Boosting - Accuracy: 0.87, ROC-AUC: 0.91
âœ“ Best model saved to models/best_model.pkl
âœ“ Preprocessor saved to models/preprocessor.pkl
```

#### Step 3.2: View MLflow Experiments
```bash
mlflow ui
```
Then open browser: `http://localhost:5000`

---

### Phase 4: Testing 

#### Step 4.1: Run Unit Tests
```bash
pytest tests/ -v --cov=src --cov-report=html
```

**Expected Output:**
```
tests/test_preprocessing.py âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“ (10 passed)
tests/test_model.py âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“ (8 passed)
tests/test_api.py âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“ (12 passed)

Total: 30 tests passed
Coverage: 85%
```

#### Step 4.2: View Coverage Report
```bash
open htmlcov/index.html
```

---

### Phase 5: API Testing 

#### Step 5.1: Start API Server
```bash
uvicorn src.app:app --reload --host 0.0.0.0 --port 8000
```

**Expected Output:**
```
INFO: Uvicorn running on http://0.0.0.0:8000
INFO: Application startup complete
```

#### Step 5.2: Test API Endpoints

**Terminal 2 - Health Check:**
```bash
curl http://localhost:8000/health
```
**Expected:** `{"status":"healthy","model_loaded":true}`

**Terminal 2 - Single Prediction:**
```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d @sample_input.json
```

**Expected Response:**
```json
{
  "prediction": 1,
  "prediction_label": "Heart Disease",
  "probability": 0.78,
  "model_version": "1.0.0"
}
```

#### Step 5.3: Access API Documentation
Open browser: `http://localhost:8000/docs`

**Screenshots:**
- Swagger UI
- /predict endpoint test
- Response JSON

---

### Phase 6: Docker Containerization 

#### Step 6.1: Build Docker Image
```bash
docker build -t heart-disease-mlops:latest .
```


#### Step 6.2: Run Docker Container
```bash
docker run -d -p 8000:8000 --name heart-disease-api heart-disease-mlops:latest
```

#### Step 6.3: Test Containerized API
```bash
# Wait 10 seconds for startup
sleep 10

# Test health endpoint
curl http://localhost:8000/health

# Test prediction
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d @sample_input.json
```

#### Step 6.4: View Container Logs
```bash
docker logs heart-disease-api
```


#### Step 6.5: Stop Container
```bash
docker stop heart-disease-api
docker rm heart-disease-api
```

---

### Phase 7: Monitoring Stack 

#### Step 7.1: Start Prometheus + Grafana
```bash
docker-compose up -d
```

#### Step 7.2: Access Dashboards
- **Prometheus:** `http://localhost:9090`
- **Grafana:** `http://localhost:3000` (admin/admin)

#### Step 7.3: Generate API Traffic
```bash
# Run this script to generate requests
for i in {1..100}; do
  curl -X POST http://localhost:8000/predict \
    -H "Content-Type: application/json" \
    -d @sample_input.json
  sleep 0.1
done
```

#### Step 7.4: View Metrics
In Grafana:
1. Add Prometheus data source: `http://prometheus:9090`
2. Import dashboard or create custom panels
3. View metrics: request_count, request_duration, prediction_count

---

### Phase 8: Kubernetes Deployment

#### Option A: Local Minikube

**Step 8.1: Start Minikube**
```bash
minikube start --driver=docker
```

**Step 8.2: Load Docker Image**
```bash
minikube image load heart-disease-mlops:latest
```

**Step 8.3: Deploy to Kubernetes**
```bash
kubectl apply -f deployment/kubernetes/deployment.yaml
kubectl apply -f deployment/kubernetes/ingress.yaml
```

**Step 8.4: Check Deployment**
```bash
kubectl get deployments
kubectl get pods
kubectl get services
```

**Step 8.5: Access Service**
```bash
minikube service heart-disease-api
```

#### Option B: Cloud Deployment (GKE/EKS/AKS)

See detailed instructions in `docs/deployment_guide.md`

---

### Phase 9: CI/CD Validation (5 minutes)

#### Step 9.1: Review GitHub Actions Workflow
```bash
cat .github/workflows/ci-cd.yml
```

#### Step 9.2: Push to GitHub
```bash
git init
git add .
git commit -m "Complete MLOps pipeline implementation"
git branch -M main
git remote add origin <your-repo-url>
git push -u origin main
```

#### Step 9.3: Monitor Workflow
Go to GitHub â†’ Actions tab â†’ View workflow runs

---